{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "import scipy.stats as stats\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import TransformerMixin # this allows us to create a custom transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs = pd.read_csv('./petfinder_data/dogs.csv')\n",
    "cats = pd.read_csv('./petfinder_data/cats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADDED DESCRIPTION LENGTH COLUMN!\n",
    "dogs['desc_len'] = [len(x) for x in dogs['Description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs['AdoptionSpeed']=dogs['AdoptionSpeed'].replace(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs['AdoptionSpeed']=dogs['AdoptionSpeed'].replace(4,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs['AdoptionSpeed']=dogs['AdoptionSpeed'].replace(3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs['AdoptionSpeed']=dogs['AdoptionSpeed'].replace(1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs['AdoptionSpeed']=dogs['AdoptionSpeed'].replace(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3484\n",
       "0    3137\n",
       "Name: AdoptionSpeed, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dogs.AdoptionSpeed.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3484\n",
       "0    3137\n",
       "Name: AdoptionSpeed, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dogs.AdoptionSpeed.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating list of columns to drop\n",
    "drops = ['Name', 'RescuerID', 'Description', 'PetID', 'AdoptionSpeed']\n",
    "\n",
    "# Dropping columns from data frame and dummifying categorical columns\n",
    "X = dogs.drop(columns=drops)\n",
    "y = dogs['AdoptionSpeed']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.25,\n",
    "    stratify=y,\n",
    "    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss =StandardScaler()\n",
    "Z_train = ss.fit_transform(X_train)\n",
    "Z_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 240 ms, sys: 6.29 ms, total: 247 ms\n",
      "Wall time: 50.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr_train = lr.score(X_train, y_train)\n",
    "lr_test = lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.5280966767371601\n",
      "test score: 0.538647342995169\n"
     ]
    }
   ],
   "source": [
    "print(f'train score: {lr_train}')\n",
    "print(f'test score: {lr_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.526205\n",
       "0    0.473795\n",
       "Name: AdoptionSpeed, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline\n",
    "dogs['AdoptionSpeed'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=lr.predict(X_test)\n",
    "y_pred[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area Under Curve: 0.5170862980540707\n"
     ]
    }
   ],
   "source": [
    "print(f'Area Under Curve: {metrics.roc_auc_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[ 80 705]\n",
      " [ 59 812]]\n",
      "\n",
      "Accuracy: 0.54\n",
      "\n",
      "Micro Precision: 0.54\n",
      "Micro Recall: 0.54\n",
      "Micro F1-score: 0.54\n",
      "\n",
      "Macro Precision: 0.56\n",
      "Macro Recall: 0.52\n",
      "Macro F1-score: 0.43\n",
      "\n",
      "Weighted Precision: 0.55\n",
      "Weighted Recall: 0.54\n",
      "Weighted F1-score: 0.44\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 1       0.58      0.10      0.17       785\n",
      "     Class 2       0.54      0.93      0.68       871\n",
      "\n",
      "    accuracy                           0.54      1656\n",
      "   macro avg       0.56      0.52      0.43      1656\n",
      "weighted avg       0.55      0.54      0.44      1656\n",
      "\n"
     ]
    }
   ],
   "source": [
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion)\n",
    "\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "print('Micro Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='micro')))\n",
    "print('Micro Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='micro')))\n",
    "print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_test, y_pred, average='micro')))\n",
    "\n",
    "print('Macro Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='macro')))\n",
    "print('Macro Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='macro')))\n",
    "print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_test, y_pred, average='macro')))\n",
    "\n",
    "print('Weighted Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='weighted')))\n",
    "print('Weighted Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='weighted')))\n",
    "print('Weighted F1-score: {:.2f}'.format(f1_score(y_test, y_pred, average='weighted')))\n",
    "\n",
    "print('\\nClassification Report\\n')\n",
    "print(classification_report(y_test, y_pred, target_names=['Class 1', 'Class 2']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline and gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>MaturitySize</th>\n",
       "      <th>FurLength</th>\n",
       "      <th>Vaccinated</th>\n",
       "      <th>Dewormed</th>\n",
       "      <th>Sterilized</th>\n",
       "      <th>Health</th>\n",
       "      <th>...</th>\n",
       "      <th>Breed_82</th>\n",
       "      <th>Breed_83</th>\n",
       "      <th>Breed_85</th>\n",
       "      <th>Breed_88</th>\n",
       "      <th>Breed_93</th>\n",
       "      <th>Breed_96</th>\n",
       "      <th>Breed_97</th>\n",
       "      <th>Breed_98</th>\n",
       "      <th>Breed_99</th>\n",
       "      <th>desc_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Brisco</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Miko</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Hunter</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Bear</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Peanut</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 148 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Type    Name  Age  Gender  MaturitySize  FurLength  Vaccinated  Dewormed  \\\n",
       "0     1  Brisco    1       1             2          2           1         1   \n",
       "1     1    Miko    4       2             2          1           1         1   \n",
       "2     1  Hunter    1       1             2          1           2         2   \n",
       "3     1    Bear    2       1             2          1           2         1   \n",
       "4     1  Peanut    2       1             2          3           1         1   \n",
       "\n",
       "   Sterilized  Health  ...  Breed_82  Breed_83 Breed_85  Breed_88  Breed_93  \\\n",
       "0           2       1  ...         0         0        0         0         0   \n",
       "1           2       1  ...         0         0        0         0         0   \n",
       "2           2       1  ...         0         0        0         0         0   \n",
       "3           2       1  ...         0         0        0         0         0   \n",
       "4           2       1  ...         0         0        0         0         0   \n",
       "\n",
       "  Breed_96 Breed_97  Breed_98  Breed_99  desc_len  \n",
       "0        0        0         0         0       393  \n",
       "1        0        0         0         0       146  \n",
       "2        0        0         0         0       390  \n",
       "3        0        0         0         0        68  \n",
       "4        0        0         0         0       345  \n",
       "\n",
       "[5 rows x 148 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dogs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating list of columns to drop\n",
    "drops = ['Name', 'RescuerID', 'PetID', 'AdoptionSpeed', 'Type']\n",
    "\n",
    "# Dropping columns from data frame and dummifying categorical columns\n",
    "X = dogs['Description']\n",
    "y = dogs['AdoptionSpeed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.25,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvec = TfidfVectorizer()\n",
    "#tvec.fit(X_train)\n",
    "#X_train = tvec.transform(X_train).todense()   # error in this cell????\n",
    "#X_test = tvec.transform(X_test).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look into svd for dimensionality reduction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[CV] tf__max_features=100, tf__ngram_range=(1, 1), tf__stop_words=english \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  tf__max_features=100, tf__ngram_range=(1, 1), tf__stop_words=english, total=   0.3s\n",
      "[CV] tf__max_features=100, tf__ngram_range=(1, 1), tf__stop_words=english \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  tf__max_features=100, tf__ngram_range=(1, 1), tf__stop_words=english, total=   0.2s\n",
      "[CV] tf__max_features=100, tf__ngram_range=(1, 1), tf__stop_words=english \n",
      "[CV]  tf__max_features=100, tf__ngram_range=(1, 1), tf__stop_words=english, total=   0.2s\n",
      "[CV] tf__max_features=100, tf__ngram_range=(1, 1), tf__stop_words=None \n",
      "[CV]  tf__max_features=100, tf__ngram_range=(1, 1), tf__stop_words=None, total=   0.3s\n",
      "[CV] tf__max_features=100, tf__ngram_range=(1, 1), tf__stop_words=None \n",
      "[CV]  tf__max_features=100, tf__ngram_range=(1, 1), tf__stop_words=None, total=   0.2s\n",
      "[CV] tf__max_features=100, tf__ngram_range=(1, 1), tf__stop_words=None \n",
      "[CV]  tf__max_features=100, tf__ngram_range=(1, 1), tf__stop_words=None, total=   0.3s\n",
      "[CV] tf__max_features=500, tf__ngram_range=(1, 1), tf__stop_words=english \n",
      "[CV]  tf__max_features=500, tf__ngram_range=(1, 1), tf__stop_words=english, total=   0.3s\n",
      "[CV] tf__max_features=500, tf__ngram_range=(1, 1), tf__stop_words=english \n",
      "[CV]  tf__max_features=500, tf__ngram_range=(1, 1), tf__stop_words=english, total=   0.3s\n",
      "[CV] tf__max_features=500, tf__ngram_range=(1, 1), tf__stop_words=english \n",
      "[CV]  tf__max_features=500, tf__ngram_range=(1, 1), tf__stop_words=english, total=   0.3s\n",
      "[CV] tf__max_features=500, tf__ngram_range=(1, 1), tf__stop_words=None \n",
      "[CV]  tf__max_features=500, tf__ngram_range=(1, 1), tf__stop_words=None, total=   0.3s\n",
      "[CV] tf__max_features=500, tf__ngram_range=(1, 1), tf__stop_words=None \n",
      "[CV]  tf__max_features=500, tf__ngram_range=(1, 1), tf__stop_words=None, total=   0.3s\n",
      "[CV] tf__max_features=500, tf__ngram_range=(1, 1), tf__stop_words=None \n",
      "[CV]  tf__max_features=500, tf__ngram_range=(1, 1), tf__stop_words=None, total=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:    3.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('tf', TfidfVectorizer()),\n",
       "                                       ('lr',\n",
       "                                        LogisticRegression(solver='saga'))]),\n",
       "             param_grid={'tf__max_features': [100, 500],\n",
       "                         'tf__ngram_range': [(1, 1)],\n",
       "                         'tf__stop_words': ['english', None]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate pipeline.\n",
    "pipe_tf = Pipeline([\n",
    "    ('tf', TfidfVectorizer()),\n",
    "    ('lr', LogisticRegression(solver = 'saga'))\n",
    "])\n",
    "\n",
    "# Define grid of parameters to GridSearch over.\n",
    "params_grid = {\n",
    "    'tf__max_features': [100, 500],\n",
    "    'tf__stop_words': ['english', None],\n",
    "    'tf__ngram_range': [(1,1)]\n",
    "}\n",
    "\n",
    "# GridSearch over pipeline with given grid of parameters.\n",
    "gs_tf = GridSearchCV(pipe_tf, params_grid, cv=3, verbose=2)\n",
    "\n",
    "# Fit model.\n",
    "gs_tf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
